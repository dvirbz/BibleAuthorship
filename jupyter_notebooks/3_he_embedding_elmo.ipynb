{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bible Authorship\n",
    "Authors: <a href=\"mailto:razmalkau@gmail.com\">Raz Malka</a> and <a href=\"mailto:shoham39@gmail.com\">Shoham Yamin</a>\n",
    "under the supervision of <a href=\"mailto:vlvolkov@braude.ac.il\">Prof. Zeev Volkovich</a> and <a href=\"mailto:r_avros@braude.ac.il@braude.ac.il\">Dr. Renata Avros</a>.\\\n",
    "Source:</br> https://github.com/ShohamYamin/BibleAuthorship/\n",
    "\n",
    "# 3. Word Embedding - ELMo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - General\n",
    "A prerequisite to this notebook is HIT-SCIR's <mark>ELMoForManyLangs</mark>, which can be installed by running the following cell.\\\n",
    "Moreover, their <a href=\"http://vectors.nlpl.eu/repository/11/154.zip\">pre-trained Hebrew model</a> is required and has to be extracted under 'models\\pretrained\\he_elmo_model' relative to the path of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ELMoForManyLangs' already exists and is not an empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/Raz/jupyter_notebooks/AAiB/submittion/ELMoForManyLangs\n",
      "Requirement already satisfied: torch in c:\\programdata\\anaconda3\\lib\\site-packages (from elmoformanylangs==0.0.4.post2) (1.8.0+cu111)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from elmoformanylangs==0.0.4.post2) (2.10.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from elmoformanylangs==0.0.4.post2) (1.19.2)\n",
      "Requirement already satisfied: overrides in c:\\programdata\\anaconda3\\lib\\site-packages (from elmoformanylangs==0.0.4.post2) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch->elmoformanylangs==0.0.4.post2) (3.7.4.3)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from h5py->elmoformanylangs==0.0.4.post2) (1.15.0)\n",
      "Installing collected packages: elmoformanylangs\n",
      "  Attempting uninstall: elmoformanylangs\n",
      "    Found existing installation: elmoformanylangs 0.0.4.post2\n",
      "    Uninstalling elmoformanylangs-0.0.4.post2:\n",
      "      Successfully uninstalled elmoformanylangs-0.0.4.post2\n",
      "  Running setup.py develop for elmoformanylangs\n",
      "Successfully installed elmoformanylangs\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/HIT-SCIR/ELMoForManyLangs.git\n",
    "!pip install -e ELMoForManyLangs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us import the required modules for this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import aaib_util as util\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from ELMoForManyLangs.elmoformanylangs.elmo import Embedder\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Loading Preprocessed Books\n",
    "The data prepared in the previous task <mark>Preprocessing and Dividing</mark> has to be loaded into memory to be used programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = []\n",
    "for i in range(len(util.books)):\n",
    "    with open(util.file_path + \"json\\\\\" + util.books[i] + \".json\", \"r\") as fp:\n",
    "        collection.append(json.load(fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Embedding with ELMoForManyLangs\n",
    "Now that the data is loaded into memory, we can use <mark>ELMoForManyLangs</mark> to perform word embedding with the Hebrew texts.\\\n",
    "The used model is 'he_elmo_model', but it can be used accordingly for any other language supported by HIT-SCIR's repository.\n",
    "\n",
    "<b>Note:</b> An embedding process with ELMo for the entire Hebrew Bible may take some time and up to 2GB of storage.\\\n",
    "For instance, it takes roughly ~12 minutes on a machine with 32GB RAM, 9th Generation Intel i7 Processor and NVIDIA RTX 2060 GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:10:40,118 INFO: char embedding size: 2289\n",
      "2021-06-15 03:10:40,901 INFO: word embedding size: 189561\n",
      "2021-06-15 03:10:43,633 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(189561, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(2289, 50, padding_idx=2286)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "2021-06-15 03:10:45,385 INFO: 3 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Genesis (1/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:11:27,276 INFO: 3 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Exodus (2/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:12:02,985 INFO: 2 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Leviticus (3/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:12:28,051 INFO: 3 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Numeri (4/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:13:02,737 INFO: 2 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Deuteronomium (5/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:13:31,867 INFO: 2 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Josua (6/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:13:54,957 INFO: 2 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Judices (7/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:14:18,246 INFO: 2 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Samuel_I (8/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:14:46,461 INFO: 2 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Samuel_II (9/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:15:10,680 INFO: 2 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Reges_I (10/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:15:38,189 INFO: 2 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Reges_II (11/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:16:04,227 INFO: 3 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Jesaia (12/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:16:41,808 INFO: 3 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Jeremia (13/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:17:26,088 INFO: 3 batches, avg len: 130.0\n",
      "2021-06-15 03:18:05,204 INFO: 1 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Ezechiel (14/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:18:12,304 INFO: 1 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Hosea (15/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:18:17,020 INFO: 1 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Joel (16/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:18:24,197 INFO: 1 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Amos (17/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:18:27,693 INFO: 1 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Obadia (18/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:18:32,721 INFO: 1 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Jona (19/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:18:38,804 INFO: 1 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Micha (20/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:18:43,187 INFO: 1 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Nahum (21/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:18:48,114 INFO: 1 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Habakuk (22/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:18:52,744 INFO: 1 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Zephania (23/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:18:57,377 INFO: 1 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Haggai (24/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:19:06,155 INFO: 1 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Sacharia (25/39)\n",
      "ELMo Word Embedding Completed for Maleachi (26/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:19:12,368 INFO: 3 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Psalmi (27/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:19:54,584 INFO: 2 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Iob (28/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:20:16,209 INFO: 1 batches, avg len: 130.0\n",
      "2021-06-15 03:20:31,309 INFO: 1 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Proverbia (29/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:20:37,015 INFO: 1 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Ruth (30/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:20:42,467 INFO: 1 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Canticum (31/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:20:52,019 INFO: 1 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Ecclesiastes (32/39)\n",
      "ELMo Word Embedding Completed for Threni (33/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:20:59,921 INFO: 1 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Esther (34/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:21:09,859 INFO: 1 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Daniel (35/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:21:23,859 INFO: 1 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Esra (36/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:21:35,770 INFO: 1 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Nehemia (37/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:21:49,896 INFO: 2 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Chronica_I (38/39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 03:22:17,705 INFO: 2 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Word Embedding Completed for Chronica_II (39/39)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntry:\\n    e = Embedder(\\'models\\\\pretrained\\\\he_elmo_model\\')\\nexcept:\\n    print(\"Embedding Failed.\")\\nelse:\\n    embeddings = []\\n    for i in range(len(util.books)):\\n        embeddings.append(e.sents2elmo(collection[i]))\\n        print(\"ELMo Word Embedding Completed for {} ({}/{})\".format(util.books[i], i + 1, len(util.books)))\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = Embedder('models\\\\pretrained\\\\he_elmo_model')\n",
    "embeddings = []\n",
    "for i in range(len(util.books)):\n",
    "    embeddings.append(e.sents2elmo(collection[i]))\n",
    "    print(\"ELMo Word Embedding Completed for {} ({}/{})\".format(util.books[i], i + 1, len(util.books)))\n",
    "    \n",
    "\"\"\"\n",
    "try:\n",
    "    e = Embedder('models\\\\pretrained\\\\he_elmo_model')\n",
    "except:\n",
    "    print(\"Embedding Failed.\")\n",
    "else:\n",
    "    embeddings = []\n",
    "    for i in range(len(util.books)):\n",
    "        embeddings.append(e.sents2elmo(collection[i]))\n",
    "        print(\"ELMo Word Embedding Completed for {} ({}/{})\".format(util.books[i], i + 1, len(util.books)))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Saving the Embeddings\n",
    "After the word embedding process has completed, generated data should be saved locally for future use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(util.books)):\n",
    "    with open(util.file_path + \"npy_elmo\\\\embedded\\\\\" + util.books[i] + \".npy\", \"wb\") as fp:\n",
    "        np.save(fp, np.array(embeddings[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
